---
layout: post
title: "IN5400 - Machine learning for image analysis"
author: Vegard Bergsvik Øvstegård
date: 21-01-2020
description: "Kompendium IN5400"
geometry: margin=2cm
tags: [IN5400]
image:
   feature: in5400.jpg
---

<details><summary markdown="span"><code>Contents</code></summary>
* TOC
{:toc}
</details>

# Week 1

## General image analysis applications
* Object detection
* Instance segmentation
* Variational Autoencoders
* Combining recurrent and convolutuional networks for image captioning 
* Reinforcement learning for games 

## Challanges with deep learning
* Training data: data with known objects used to find the weights in the net
* Validation data: data with known objects used to select architectures and
hyperparameters
* Test data: data with known objects used once to estimate the error rate of the system
* Overfitting to training data
* Working with skewed data
    * When challanged with a dataset that has mostly unimportant classes, and few samples of important classes. How to avoid fitting the model to the unimportant classes, and focus og the small but important classes.

## Introduction to image classification
### Challanges 
* Illumination
* Occlusion
* Deformation
* Background clutter
* Interclass variation

### Measuring similarity between two images
Image F(k,i,j), pixel(i,j) in band k.
* L1-Distance:
$$d_1(i,j) = \sum_k\sum_i\sum_j|F1(k,i,j)-F2(k,i,j)|$$
* L2-Distance(Euclidean distance):
$$d_1(i,j) = \sum_k\sum_i\sum_j\sqrt{F1(k,i,j)^2-F2(k,i,j)^2}$$

### K-nearest-neighbor classification
* Given a set of images $$m$$ training images $$F(i)$$ with true class labels $$y(i), i \in{1, m}$$
* Classification of a new sample $$F(new)$$ is done as follows:
    * Out of the m training images, find the k images with smallest distance (measured by L1 or
    L2)
    * Out of these $$k$$ samples, identify the most frequent class labels
    * Assign the class label the sample as the most frequent class labels among the $$k$$ labels. Denote the predicted class as $$\hat{y}^{(i)}$$
* $$k$$ should be odd, and must be selected a priori (try different values of $$k$$ and choose the one with the lowest classification error using crossvalidation)
* Classification error can be measured by counting the number of samples where the predicted class is equal to the true class $$\hat{y}^{(i)} = y^{(i)}$$

### Selecting K using crossvalidation
For each value of k:
* Cross-validation: split the training data into d subset/folds
* Train on data from d-1 folds ,
* Estimate the accuracy/compute the number of correctly classified images on the last
fold , store the accuracy.
* Repeat this nfold times and compute for the average of the accuracies.
* Repeat with different values of k, select the value that got the highest accuary.
* Using the best value of K, classify the test data set ONCE to get the accuracy of the
classifier

### About KNN-classification
* If k = 1 (1NN-classification), each sample is assigned to the same class as the closest
sample in the training data set.
* If k is very large, this is theoretically a very good classifier.
* This classifier involves no ”training time”, but the time needed to classify one pattern xi will depend on the number of training samples, as the distance to all points in the training set must be computed.
* ”Practical” values for k: 3 ≤ k ≤ 9
* Classification performance should always be computed on the test data set.
* For image classification using the original pixel values as feature values, the results is not invariant to object position, scale, contrast!

### Image Convolution
Common operation in image analysis
* Apply pre-defined filters to enhance or highlight certain features in an image
* Examples:
* Image smoothing using e.g. an averaging filter or a Gaussian filter
* Edge detection by computing the first derivatives
* Point detection and edge locatization using second derivatives
* Classical filters are predefined, but convolutional networks will estimate filters to
locate various shapes in the image

